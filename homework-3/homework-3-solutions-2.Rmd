---
title: "Homework 3"
author: "PSTAT 131/231"
output:
    html_document:
      toc: true
      toc_float: true
      code_folding: show
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE, message = FALSE,
                      warning = FALSE)
```

## Binary Classification

For this assignment, we will be working with part of a [Kaggle data set](https://www.kaggle.com/c/titanic/overview) that was the subject of a machine learning competition and is often used for practicing ML models. The goal is classification; specifically, to predict which passengers would survive the [Titanic shipwreck](https://en.wikipedia.org/wiki/Titanic).

![Fig. 1: RMS Titanic departing Southampton on April 10, 1912.](images/RMS_Titanic.jpg){width="363"}

Load the data from `data/titanic.csv` into *R* and familiarize yourself with the variables it contains using the codebook (`data/titanic_codebook.txt`).

Notice that `survived` and `pclass` should be changed to factors. When changing `survived` to a factor, you may want to reorder the factor so that *"Yes"* is the first level.

Make sure you load the `tidyverse` and `tidymodels`!

*Remember that you'll need to set a seed at the beginning of the document to reproduce your results.*

```{r}
library(tidyverse)
library(tidymodels)
library(corrplot)
library(discrim)
library(poissonreg)
library(corrr)
tidymodels_prefer()

set.seed(3435) # can be any number

titanic <- read_csv(file = "data/titanic.csv") %>% 
  mutate(survived = factor(survived, 
                           levels = c("Yes", "No")),
         pclass = factor(pclass))
titanic
```

### Question 1

Split the data, stratifying on the outcome variable, `survived.` You should choose the proportions to split the data into. Verify that the training and testing data sets have the appropriate number of observations. Take a look at the training data and note any potential issues, such as missing data.

Why is it a good idea to use stratified sampling for this data?

```{r}
titanic_split <- titanic %>% 
  initial_split(strata = survived, prop = 0.7)
titanic_train <- training(titanic_split)
titanic_test <- testing(titanic_split)
dim(titanic_train)
dim(titanic_test)
```

*Each dataset has approximately the right number of observations;* $623$ is almost exactly $70\%$ of the full data set, which contains $891$ observations.

*It's probably a good idea to use stratified sampling here because the outcome variable is imbalanced; there are more observations for one level, 'No', than the other, 'Yes'.*

*One relatively easy way to summarize the data is `summary()`:*

```{r}
titanic_train %>%
  summary()
```

*The only variable with missingness is `age`, which is missing* $136$ observations.

### Question 2

Using the **training** data set, explore/describe the distribution of the outcome variable `survived`.

*A bar chart is probably the easiest way to assess it, although virtually any method of assessing the counts per level is fine:*

```{r}
titanic_train %>% 
  ggplot(aes(x = survived)) +
  geom_bar()
```

Create a [percent stacked bar chart](https://r-graph-gallery.com/48-grouped-barplot-with-ggplot2) (recommend using `ggplot`) with `survived` on the *x*-axis and `fill = sex`. Do you think `sex` will be a good predictor of the outcome?

```{r}
titanic_train %>% 
  ggplot(aes(x = survived, fill = sex)) +
  geom_bar(position = "fill")
```

*Answers may vary but should say that **yes**, sex most likely will be useful in predicting the outcome `survived`. A much greater proportion of `male`s than `female`s did not survive.*

Create one more percent stacked bar chart of `survived`, this time with `fill = pclass`. Do you think passenger class will be a good predictor of the outcome?

```{r}
titanic_train %>% 
  ggplot(aes(x = survived, fill = pclass)) +
  geom_bar(position = "fill")
```

*Again, answers may vary, but should generally say that **yes**, `pclass` will probably be a good/useful predictor of the outcome. There are much higher proportions of third-class passengers in particular that did not survive.*

Why do you think it might be more useful to use a [percent stacked bar chart](https://r-graph-gallery.com/48-grouped-barplot-with-ggplot2) as opposed to a traditional stacked bar chart?

*The main difference, and reason it can be more useful in situations like this, is because if we made a traditional bar chart of the counts broken down by `sex` or `pclass`, it would be virtually impossible to tell whether the proportion of each level of `sex` or `pclass` differed across levels of the outcome. Using proportions rather than counts makes things easier.*

### Question 3

Using the **training** data set, create a correlation matrix of all continuous variables. Visualize the matrix and describe any patterns you see. Are any predictors correlated with each other? Which ones, and in which direction?

```{r}
titanic_train %>% 
  select(is.numeric, -passenger_id) %>% 
  cor(use = "complete.obs") %>% 
  corrplot(type = "lower", diag = FALSE)
```

*`age` and `sib_sp` are negatively correlated, which implies that older passengers are less likely to have siblings on board. `parch` and `sib_sp` are positively correlated, which implies that having one on board means having the other on board is also likely.*

*Note that it's technically possible to argue that `sib_sp` and `parch` shouldn't be included because they are count variables, therefore not continuous (more ordinal, really).*

### Question 4

Using the **training** data, create a recipe predicting the outcome variable `survived`. Include the following predictors: ticket class, sex, age, number of siblings or spouses aboard, number of parents or children aboard, and passenger fare.

Recall that there were missing values for `age`. To deal with this, add an imputation step using `step_impute_linear()`. Next, use `step_dummy()` to **dummy** encode categorical predictors. Finally, include interactions between:

-   Sex and passenger fare, and
-   Age and passenger fare.

You'll need to investigate the `tidymodels` documentation to find the appropriate step functions to use.

```{r}
titanic_recipe <- recipe(survived ~ pclass + sex + age + 
                           sib_sp + parch + fare, titanic_train) %>% 
  step_impute_linear(age, impute_with = imp_vars(sib_sp)) %>% 
  # choice of predictors to impute with is up to you
  step_dummy(all_nominal_predictors()) %>% 
  step_interact(~ starts_with("sex"):age + age:fare)
```

*Since the question doesn't specify, students can use basically any variables to impute `age` with; doesn't have to be `sib_sp`.*

### Question 5

Specify a **logistic regression** model for classification using the `"glm"` engine. Then create a workflow. Add your model and the appropriate recipe. Finally, use `fit()` to apply your workflow to the **training** data.

***Hint: Make sure to store the results of `fit()`. You'll need them later on.***

```{r}
log_reg <- logistic_reg() %>% 
  set_engine("glm") %>% 
  set_mode("classification")

log_wkflow <- workflow() %>% 
  add_model(log_reg) %>% 
  add_recipe(titanic_recipe)

log_fit <- fit(log_wkflow, titanic_train)
```

### Question 6

**Repeat Question 5**, but this time specify a linear discriminant analysis model for classification using the `"MASS"` engine.

```{r}
lda_mod <- discrim_linear() %>% 
  set_mode("classification") %>% 
  set_engine("MASS")

lda_wkflow <- workflow() %>% 
  add_model(lda_mod) %>% 
  add_recipe(titanic_recipe)

lda_fit <- fit(lda_wkflow, titanic_train)
```

### Question 7

**Repeat Question 5**, but this time specify a quadratic discriminant analysis model for classification using the `"MASS"` engine.

```{r}
qda_mod <- discrim_quad() %>% 
  set_mode("classification") %>% 
  set_engine("MASS")

qda_wkflow <- workflow() %>% 
  add_model(qda_mod) %>% 
  add_recipe(titanic_recipe)

qda_fit <- fit(qda_wkflow, titanic_train)
```

### Question 8

**Repeat Question 5**, but this time specify a *k*-nearest neighbors model for classification using the `"kknn"` engine. Choose a value for *k* to try.

```{r}
knn_mod <- nearest_neighbor(neighbors = 6) %>% 
  set_mode("classification") %>% 
  set_engine("kknn")

knn_wkflow <- workflow() %>% 
  add_model(knn_mod) %>% 
  add_recipe(titanic_recipe)

knn_fit <- fit(knn_wkflow, titanic_train)
```

*Basically any value of k that they want to try is fine.*

### Question 9

Now you've fit four different models to your training data.

Use `predict()` and `bind_cols()` to generate predictions using each of these 4 models and your **training** data. Then use the metric of **area under the ROC curve** to assess the performance of each of the four models.

*Note: They can also simply use `augment()` which, honestly, is probably easier, as shown below. Students should not lose points for using `augment()` instead; it does the same thing but with fewer lines.*

```{r}
log_auc <- augment(log_fit, new_data = titanic_train) %>% 
  roc_auc(survived, .pred_Yes)
lda_auc <- augment(lda_fit, new_data = titanic_train) %>% 
  roc_auc(survived, .pred_Yes)
qda_auc <- augment(qda_fit, new_data = titanic_train) %>% 
  roc_auc(survived, .pred_Yes)
knn_auc <- augment(knn_fit, new_data = titanic_train) %>% 
  roc_auc(survived, .pred_Yes)

results <- bind_rows(log_auc, lda_auc, qda_auc, knn_auc) %>% 
  tibble() %>% mutate(model = c("Logistic", "LDA", "QDA", "KNN")) %>% 
  select(model, .estimate) %>% 
  arrange(.estimate)

results
```

*KNN will most likely perform the best in terms of area under the ROC curve on the **training** data, in large part because KNN is a very data-driven (and nonparametric) model, and will almost always do quite well at predicting the data it was fit to. This is probably overfitting. QDA, LDA, and logistic regression do almost interchangeably.*

### Question 10

Fit all four models to your **testing** data and report the AUC of each model on the **testing** data. Which model achieved the highest AUC on the **testing** data?

```{r}
log_auc_test <- augment(log_fit, new_data = titanic_test) %>% 
  roc_auc(survived, .pred_Yes)
lda_auc_test <- augment(lda_fit, new_data = titanic_test) %>% 
  roc_auc(survived, .pred_Yes)
qda_auc_test <- augment(qda_fit, new_data = titanic_test) %>% 
  roc_auc(survived, .pred_Yes)
knn_auc_test <- augment(knn_fit, new_data = titanic_test) %>% 
  roc_auc(survived, .pred_Yes)

results_test <- bind_rows(log_auc_test, lda_auc_test, 
                          qda_auc_test, knn_auc_test) %>% 
  tibble() %>% mutate(model = c("Logistic", "LDA", "QDA", "KNN")) %>% 
  select(model, .estimate) %>% 
  arrange(.estimate)

results_test
```

*On the testing data, the model that performs the best may slightly vary, since we randomly split the data into training and testing. In most cases it will probably be either LDA or logistic regression, with KNN in third. QDA usually will do a bit worse.*

Using your top-performing model, create a confusion matrix and visualize it. Create a plot of its ROC curve.

```{r}
augment(log_fit, new_data = titanic_test) %>% 
  conf_mat(truth = survived, estimate = .pred_class) %>% 
  autoplot(type = "heatmap")
```

```{r}
augment(log_fit, new_data = titanic_test) %>%
  roc_curve(survived, .pred_Yes) %>%
  autoplot()
```

How did your best model perform? Compare its **training** and **testing** AUC values. If the values differ, why do you think this is so?

*The model actually did quite well, and its accuracy slightly increased on the testing data. This is likely because the model is **very** mechanistic, so it has lower variance.*

### Required for 231 Students

In a binary classification problem, let $p$ represent the probability of class label $1$, which implies that $1 - p$ represents the probability of class label $0$. The *logistic function* (also called the "inverse logit") is the cumulative distribution function of the logistic distribution, which maps a real number *z* to the open interval $(0, 1)$.

### Question 11

Given that:

$$
p(z)=\frac{e^z}{1+e^z}
$$

Prove that the inverse of a logistic function is indeed the *logit* function:

$$
z(p)=ln\left(\frac{p}{1-p}\right)
$$

*To show that the inverse of the logistic function is the logit function, we can start with the logistic function:*

$$
P(z) = \frac{e^z}{1+e^z}
$$

*We'll set* $P(z)=y$ for simplicity.

$$
y+ye^z=e^z
$$

$$
y=e^z-ye^z
$$

$$
y=(1-y)e^z
$$

$$
e^z=\frac{y}{1-y}
$$

$$
ln(e^z)=ln(\frac{y}{1-y})
$$

$$
z=ln(\frac{y}{1-y})
$$

$$
z(p)=ln(\frac{p}{1-p})
$$

### Question 12

Assume that $z = \beta_0 + \beta_{1}x_{1}$ and $p = logistic(z)$. How do the odds of the outcome change if you increase $x_{1}$ by two? Demonstrate this.

Assume now that $\beta_1$ is negative. What value does $p$ approach as $x_{1}$ approaches $\infty$? What value does $p$ approach as $x_{1}$ approaches $-\infty$? Demonstrate.

*If you increase* $x_{1}$ *by two, the odds of the outcome increase* $e^{2\beta_{1}}$ *times. If* $\beta_{1}$ *is negative, as* $x_{1} \rightarrow \infty$*,* $\frac{p}{1-p}$ *approaches* $0$*, and vice versa; as* $x_{1} \rightarrow -\infty$*,* $\frac{p}{1-p}$ *approaches* $1$*.*
